# Containers

Gives lot of security & resource management features

Docker Image → can consider them as a blueprints of some already made containers

Docker Images as a drawing or picture of ur fav toys

It contains details of your toys look

## Docker Containers

It is like a magical Box that can hold your fav toy inside

When you add your image you can use this magical box to create an exact copy of your toy

Definition → Docker images is a snapshot or a blueprint of a complete environment for an application

It includes everything like what the application needs to run such as libraries,  dependencies, config etc…

It kind of encapsulates the app & all the req together.

Containers → it is an actual running instance of the environment configured by the image

when we run a docker image, it creates a live & running container.

This containers are isolated & very light weight virtual machines

A big difference between containers & VM’s is that containers share the host OS kernel & this sharing make them light weight

# Getting Started with Docker

Docker is **an open-source platform that allows developers to package, distribute, and run applications using containers**. These containers are lightweight, portable, and self-contained, meaning they include everything an application needs to run, such as code, runtime, libraries, and system tools. Docker simplifies application deployment, scaling, and management, making it easier to build, test, and deploy applications in various environments.

### Difference between Docker Images & Docker Container

**A Docker image is a read-only template containing instructions for building a container, including the application code, runtime, system tools, libraries, and settings.**

**A Docker container, on the other hand, is a runtime instance of a Docker image, running the application and its components in an isolated environment**. 

Think of an image as the blueprint and a container as the built structure, where multiple containers can be created from the same image.

Here's a more detailed breakdown:

**Docker Image:**

- **Template:** It's a read-only template that defines the environment for a container.
- **Immutable:** Images are designed to be immutable, meaning they cannot be directly modified after creation. To make changes, a new image must be built from a modified Dockerfile.
- **Foundation:** It acts as the foundation for creating and running containers.
- **Distribution:** Images are designed to be shared, stored in registries, and transported between systems.

**Docker Container:**

- **Runtime Instance:** A container is a running instance of an image.
- **Isolated Environment:** Each container provides an isolated environment for the application, separating it from the host system and other containers.
- **Mutable:** Containers are mutable, meaning changes can be made to them during runtime (e.g., adding files, modifying code).
- **Ephemeral:** Containers are generally ephemeral, meaning their state (changes made during runtime) is lost when the container is stopped or deleted.
- **Lifecycle:** Containers have a lifecycle (running, stopped, paused, etc.) and can be created, destroyed, and managed using the Docker API or CLI.

In essence, a Docker image is the recipe, while a container is a running instance of that recipe. You can create multiple containers from the same image, but each container will have its own data and state, according to Stack Overflow

Images are like blueprint, somebody has already created docker container and its configuration we can just pull the image and start running it, we can also create our own images using the docker file so that others can also use it

Docker Images are pre made containers 

### Docker Hub

Docker Hub is **a public online repository where you can find, share, and manage Docker images, which are like templates for your applications**. Think of it as a cloud-based library where developers can easily access pre-built images or upload their own. This allows for easy distribution and reuse of containerized applications

It is pre defined set of images

```docker
docker pull node -> pulls node
docker run -it --rm node
```

-it → opens interactive terminal

 --rm → automatically removes the copntainer when we exit

```docker
docker ps
```

lists the docker containers

```docker
docker kill <container_id>
```

kills the docker with the container id

```docker
docker image prune
```

any image that is not being used will be deleted

```docker
docker run -it alpine ls
```

-it → runs the docker in interactive mode

helps in running the code → ls

```docker
/ # cat /etc/issue
```

The command cat /etc/issue executed within a Docker container displays the content of the /etc/issue file. This file typically contains a text string identifying the operating system distribution running inside the container. It's a common way to quickly check the distribution, such as Ubuntu, Debian, or CentOS, and often includes the version number.

For example, if a container is running Ubuntu 20.04, the output of cat /etc/issue

might look like this:

```docker
Ubuntu 20.04 LTS \n \l
```

The `ps aux` command, when executed within a Docker container, provides a snapshot of the processes running inside that container. It displays detailed information about each process, including the user ID (UID), process ID (PID), CPU usage (%CPU), memory usage (%MEM), virtual memory size (VSZ), resident set size (RSS), terminal (TTY), status (STAT), start time (START), and the command being executed (COMMAND)

If we dont write `-it` in `docker run -it alpine` then it will execute but in exited state

to go inside the container:

```docker
docker attach <container_id>
```

The `docker attach <container_id>` command **attaches your terminal's standard input, output, and error streams to the running container**, allowing you to view its output or interact with it as if it were running directly in your terminal. This means you can see the container's logs and, if the container is running a shell, enter commands directly into the container's terminal.  

`docker attach` provides a way to directly interact with a running container's process output and potentially control it, depending on the container's entry point. 

The `docker detach <container_id>` command doesn't directly detach you from a running container to access its shell. Instead, it's used to **start a container in the background, detaching it from the terminal**. If you want to access a container's shell, you'll need to use `docker exec -it <container_id> bash`

**Explanation:**

- **`docker detach <container_id>` (or `d`):**
    
    This command tells Docker to run the container in the background without attaching it to your terminal. You'll see the container ID printed to your terminal, but you'll be returned to your command prompt.
    

```docker
docker rm <name of the container> 
```

to delete the container

to setup a custom name

```docker
docker run -it --detach --name custom-node
```

to combine both -it & --detach → we can use -dit

```docker
docker run -dit  --name custom-node
```

```docker
docker run -it node bash
```

goes inside the bash terminal

```docker
cat /etc/issue
```

to check which linux it is

```docker
Docker inspect <name_of_the_img>
```

Gives bunch of info about that img

```docker
docker pause <container_id>
```

pauses the particular container

```docker
docker unpause <container_id>
```

unpauses the particular container

```docker
docker kill <container_id>
```

to kill a container

```docker
docker run --detach -it ubuntu
```

- **`docker run`**: Create and start a new container.
- **`-detach` (`d`)**: Run the container in the **background**.
- **`it` (`-i -t`)**: Make it **interactive** and give it a **terminal** for later access.
- **`ubuntu`**: Use the **Ubuntu operating system image**.

We use this to run a background Ubuntu environment that we can still connect to and work with later, which is great for running services and debugging.

```docker
docker exec -it rhgbebsvbbedbbeinvnejibhvbheabvjnjdfjnnregiberb bash
```

- **`docker exec`**: Execute a command inside a *running* Docker container.
- **`it` (`-i -t`)**: This makes the execution **interactive** and allocates a **pseudo-TTY** (terminal). This is crucial for getting a proper shell prompt and interacting with it.
- **`rhgbebsvbbedbbeinvnejibhvbheabvjnjdfjnnregiberb`**: This is the **ID or name of the specific running Docker container** you want to execute the command inside. Docker uses these unique identifiers to distinguish between containers.
- **`bash`**: This is the **command** you want to run *inside* the container. In this case, `bash` opens a Bash shell, giving you a command-line interface within that running container.

In simple terms, this command lets you **get an interactive command-line interface (like opening a terminal) inside a Docker container that is already running**, identified by its unique ID. This is extremely useful for debugging, inspecting, or performing administrative tasks within a container without stopping and restarting it.

Difference between docker run & docker exec

- **`docker run`**: **Starts a *new* container** from an image. (Think: "boot up a new machine")
- **`docker exec`**: **Runs a command *inside* an *already running* container.** (Think: "open a program on a running machine")

```docker
docker inspect
```

`docker inspect` is a powerful command-line tool that provides **low-level, detailed information about Docker objects**. It's like a magnifying glass for your Docker environment, revealing the intricate configurations and runtime data of various components.

Here's a breakdown of what it does and why it's so useful, especially for a DevOps aspirant:

**What it inspects:**

`docker inspect` can be used to gather information about a variety of Docker objects, including:

- **Containers:** This is one of its most common uses. You can inspect running or stopped containers to get details about their state, configuration, network settings, mounted volumes, environment variables, exposed ports, process IDs, and more.
- **Images:** It provides information about Docker images, such as their layers, size, creation date, build history, and any metadata or labels associated with them.
- **Networks:** You can inspect Docker networks to see their configuration, including subnets, gateways, connected containers, and IP address management (IPAM) details.
- **Volumes:** It shows information about Docker volumes, such as their mount point, driver, labels, and usage.
- **Other objects:** Depending on your Docker setup, it can also inspect nodes, secrets, services, tasks, and plugins in a Docker Swarm or other orchestration environments.

`docker inspect` is like a **magnifying glass** for Docker. When you use it on a Docker object (like a container, image, or network), it shows you **all the hidden details and settings** of that object in a very organized way.

Imagine you have a new toy. `docker inspect` is like getting the instruction manual and a detailed blueprint for that toy, telling you exactly:

- What it's made of
- How it's put together
- What its functions are
- Where its power source is located

For Docker, it tells you things like:

- **For a container:** Its IP address, what folders are shared with your computer, what settings it started with, if it's running, and where its logs are.
- **For an image:** All the different pieces it's built from, its size, and what it's set up to do when it runs.
- **For a network:** Which IP addresses are available, and which containers are connected to it.

It's super useful for **troubleshooting** when something isn't working right, or just to **understand exactly** how your Docker setup is configured.

In docker run you mention the name of the image

in docker exec you mention the name of the container bcz docker exec already runs on the existing containers

to create our img create a docker file

every time we want to set a container we need to add some base container

docker file is case sensitive

```docker
FROM node 
#taking base container as node
#cant have multiple CMD terms
CMD ["node", "-e", "console.log(100)"]
```

to build a docker container → `docker  build .`

docker rmi <img_id> → removes an img

docker rm <container_id> → removes container

to give a tag

```docker
docker build -t <name-of-basic-tag> .
```

to control the server from the host machine only use --init

```docker
docker run -it --init my-server:latest
```

to publish and expose the server in the host machine

```docker
docker run -it --init --publish 3001:3000 my-server:latest
```

3001 → to be used in the browser which port of the machoine to be exposed

3000 → which port of the container to be exposed

apt_get → `apt-get` is **a command-line utility used for managing software packages on Debian-based Linux distributions, such as Ubuntu**

`RUN` executes commands during the image build process, committing the results to a new image layer

`CMD` specifies the default command to be executed when a container is launched from that image, which can be overridden by arguments provided during container execution

```docker
FROM node

WORKDIR /developer/nodejs/app_from_github

RUN apt-get update && apt-get install -y git

RUN git clone https://github.com/singhsanket143/Dockerizing_node_project.git .

ENV PORT=3000

EXPOSE 3000

RUN npm ci

CMD ["npm", "start"]
```

### Explanation of the `Dockerfile`

1. **`FROM node`**
    - **Purpose:** This is the foundational instruction. It specifies the base image for your Docker image.
    - **Explanation:** You're starting your build process from an official Node.js image (likely `node:latest` by default if no tag is specified). This base image already contains Node.js and npm (Node Package Manager), providing a ready-to-use environment for a Node.js application.
2. **`WORKDIR /developer/nodejs/app_from_github`**
    - **Purpose:** Sets the working directory inside the Docker image for all subsequent `RUN`, `CMD`, `ENTRYPOINT`, `COPY`, and `ADD` instructions.
    - **Explanation:** This creates and navigates into the `/developer/nodejs/app_from_github` directory within the container. All commands that follow (like `git clone` or `npm ci`) will be executed relative to this directory. It's a best practice to define a `WORKDIR` to keep your file system organized within the image.
3. **`RUN apt-get update && apt-get install -y git`**
    - **Purpose:** Executes commands to update package lists and install `git` within the image.
    - **Explanation:**
        - `apt-get update`: Updates the package lists for upgrades and new package installations. This is crucial before installing any new software to ensure you get the latest versions and avoid dependency issues.
        - `apt-get install -y git`: Installs the `git` command-line tool. The `y` flag automatically answers "yes" to any prompts, making the installation non-interactive. `git` is needed because the next step involves cloning a Git repository.
4. **`RUN git clone https://github.com/singhsanket143/Dockerizing_node_project.git .`**
    - **Purpose:** Clones a Git repository into the current working directory.
    - **Explanation:** This command downloads the source code of the Node.js project from the specified GitHub URL into the `/developer/nodejs/app_from_github` directory (because of the `WORKDIR` instruction). The `.` at the end means "clone into the current directory," so the contents of the repository will be directly in `app_from_github`, not in a subfolder named `Dockerizing_node_project`.
5. **`ENV PORT=3000`**
    - **Purpose:** Sets an environment variable named `PORT` with the value `3000` inside the Docker image.
    - **Explanation:** Environment variables are often used by applications to configure their behavior. Many web applications, including Node.js apps, listen for incoming connections on a specific port defined by an environment variable like `PORT`. By setting this here, the Node.js application, once running, will know to listen on port 3000.
6. **`EXPOSE 3000`**
    - **Purpose:** Informs Docker that the container will listen on the specified network ports at runtime.
    - **Explanation:** This instruction is documentation. It tells anyone using this image that the application inside is designed to listen on port 3000. It *does not* actually publish the port to the host system. To make the port accessible from outside the container, you need to use the `p` or `-publish` flag with `docker run` (e.g., `docker run -p 3001:3000`).
7. **`RUN npm ci`**
    - **Purpose:** Installs Node.js dependencies.
    - **Explanation:** `npm ci` (clean install) is a more robust alternative to `npm install` for automated environments like Docker builds. It installs dependencies strictly based on `package-lock.json` (or `npm-shrinkwrap.json`), ensuring consistent builds by avoiding potential discrepancies that `npm install` might introduce if `package.json` and `package-lock.json` are out of sync. This command ensures all necessary Node.js modules for the cloned application are installed.
8. **`CMD ["npm", "start"]`**
    - **Purpose:** Provides the default command to execute when a container is started from this image.
    - **Explanation:** This defines the command that will be run when the container is launched without a specific command. In this case, it tells the container to execute `npm start`. This is a common command for Node.js applications to begin their execution, usually specified in the `package.json` file's "scripts" section.

### Commented-out `docker` Commands:

The image also shows some commented-out `docker` commands, which are useful for building and running a container from this Dockerfile:

- **`# docker build -t app-from-github-with-env .`**
    - **Purpose:** This command would build a Docker image from the `Dockerfile` in the current directory.
    - **Explanation:**
        - `docker build`: The command to build a Docker image.
        - `t app-from-github-with-env`: Tags the image with the name `app-from-github-with-env`. This makes it easier to reference the image later.
        - `.`: Specifies the build context (the current directory), meaning Docker will look for the `Dockerfile` and any related files in the current directory.
- **`# docker run --init --publish 3001:3000 app-from-github-with-env:latest`**
    - **Purpose:** This command would run a container from the `app-from-github-with-env` image.
    - **Explanation:**
        - `docker run`: The command to run a container.
        - `-init`: Runs an `init` process inside the container. This is useful for handling signal forwarding and reaping zombie processes, which is good practice for production containers.
        - `-publish 3001:3000` (or `p 3001:3000`): Maps port 3000 inside the container to port 3001 on the host machine. This means you can access the Node.js application by navigating to `http://localhost:3001` (or `http://your_host_ip:3001`) from your browser.
        - `app-from-github-with-env:latest`: Specifies the image to run (the one you just built and tagged). `:latest` is the default tag if not specified.

![image.png](attachment:2bcd2598-b2ff-4023-aca2-0e577cf0fdff:image.png)

- **`# docker build -t app-from-github-with-env .`**
    - **What it is:** A commented-out `docker build` command.
    - **Purpose:** It's an example of how you would build the Docker image defined by the `Dockerfile` above it. It's provided for convenience and clarity, so anyone using this Dockerfile knows the common command to get started. By commenting it out, it prevents the command from being accidentally run if the entire text block is copied and pasted into a script or terminal.
- **`# docker run --init --publish 3001:3000 app-from-github-with-env:latest`**
    - **What it is:** A commented-out `docker run` command.
    - **Purpose:** This shows an example of how to run a container from the image built in the previous step, specifically demonstrating how to map container port 3000 to host port 3001. Again, it's for documentation and ease of use.
- **`# docker run --init -p 3001:3000 app-from-github-with-env:latest`**
    - **What it is:** Another commented-out `docker run` command.
    - **Purpose:** This is functionally identical to the previous line, just using the shorthand `p` instead of `-publish`. It offers an alternative syntax for the same port mapping.
- **`# docker run --init -P app-from-github-with-env:latest`**
    - **What it is:** A third commented-out `docker run` command.
    - **Purpose:** This demonstrates using the `P` (capital P) flag, which automatically publishes all *exposed* ports. As noted previously, in *this specific `Dockerfile`* where `EXPOSE 3000` is commented out, this command alone wouldn't actually map any ports, as there are no exposed ports declared in the image's metadata. This line serves as an example of a common `docker run` option, though its effectiveness is dependent on the `EXPOSE` instruction in the `Dockerfile`.

[`github.com/singhsanket143/Containers/tree/master`](http://github.com/singhsanket143/Containers/tree/master) → to see the modules

for basic node server → dockerizing node project

### BIND MOUND

```bash
# Clean up the whole system and delete every image container etc:

docker system prune -a

# Build a dockerfile and create an image
# (execute the below command either from the directory where dockerfile is present, or replace . with path to dockerfile)

docker build -t <tag_name> .

# Run a container from an image

docker run --init -p <host_port>::<container_port> <image_name>

# Bind mount project with docker container

docker run --init -p 3002:3000 -v "$(pwd)":/developer/nodejs/node-bind-mound-project app-bind-mount-node:latest
```

### 1. Clean up the whole system and delete every image container etc:

**Command:** `docker system prune -a`

- **Purpose:** This command is used to clean up unused Docker objects on your system. It's a very powerful and useful command, especially for developers or in environments where you frequently create, stop, and remove Docker containers and images, as it helps free up disk space.
- **Breakdown:**
    - `docker system`: Refers to the Docker system-wide commands.
    - `prune`: The action to remove unused objects.
    - `a` or `-all`: This flag signifies a more aggressive pruning. It removes:
        - All stopped containers.
        - All dangling (not associated with any container) networks.
        - All dangling images (images that are not tagged or referenced by any container).
        - All **unused** images (images that are not associated with any running container, even if they have tags).
        - All build cache.
- **Warning:** Be careful when using `docker system prune -a` as it will remove all images that are not actively used by a running container, even if you explicitly tagged them. It's generally good practice to stop all containers you want to keep before running this command, or specify what you want to prune more precisely (e.g., `docker image prune` for just images).

### 2. Build a dockerfile and create an image

**Command:** `docker build -t <tag_name> .`

- **Purpose:** This command takes a `Dockerfile` and builds a Docker image from it.
- **Breakdown:**
    - `docker build`: The main command to initiate an image build.
    - `t <tag_name>` or `-tag <tag_name>`: This flag assigns a name and optional tag to your image.
        - `<tag_name>`: This is a placeholder. You would replace it with a meaningful name for your image, typically in the format `repository/image_name:tag`. For example, `my-app:1.0` or `myusername/nodejs-app:latest`. If you don't specify a tag (e.g., `my-app`), it defaults to `:latest`.
    - `.`: This indicates the "build context."
        - The `.` means "the current directory." Docker will look for a file named `Dockerfile` in the current directory and use all files and folders in that directory as part of the build context. It's crucial because any `COPY` or `ADD` instructions in your `Dockerfile` will refer to paths relative to this build context.
        - **Note from the comment:** The comment correctly states that you can either execute this from the directory where the `Dockerfile` resides, or replace `.` with the path to the directory containing your `Dockerfile` (e.g., `docker build -t my-app /path/to/my/app/dockerfile/directory`).

### 3. Run a container from an image

**Command (General Template):** `docker run --init -p <host_port>::<container_port> <image_name>`

- **Purpose:** This is the fundamental command to start a new container from a Docker image.
- **Breakdown:**
    - `docker run`: The command to create and start a new container.
    - `-init`: Runs an `init` process inside the container. This `init` process is essential for properly handling OS signals (like `SIGTERM` when stopping a container) and for reaping "zombie" processes (processes that have terminated but whose parent hasn't collected their exit status). It makes your containers more robust and behaves more like a standard Linux process.
    - `p <host_port>:<container_port>` or `-publish <host_port>:<container_port>`: This flag maps a port from your host machine to a port inside the Docker container.
        - `<host_port>`: The port number on *your local machine* (the host) that you want to use to access the service running inside the container.
        - `<container_port>`: The port number *inside the container* that the application is listening on (e.g., if your Node.js app listens on port 3000 inside the container, this would be 3000).
        - `::`: The image shows `::` which is a typo or specific notation. The correct syntax for port mapping is always a single colon `:` (e.g., `p 8080:80`).
    - `<image_name>`: The name (and optionally tag) of the Docker image you want to run (e.g., `nginx:latest`, `my-app:1.0`).

### 4. Bind mount project with docker container

**Command (Specific Example):** `docker run --init -p 3002:3000 -v "$(pwd)":/developer/nodejs/node-bind-mound-project app-bind-mount-node:latest`

- **Purpose:** This command runs a container, but critically, it uses a **bind mount** to synchronize a local directory on your host machine with a directory inside the container. This is extremely powerful for development workflows.
- **Breakdown:**
    - `docker run --init -p 3002:3000`: These parts are the same as explained above: start a container with `init` process and map host port `3002` to container port `3000`.
    - `v "$(pwd)":/developer/nodejs/node-bind-mound-project` or `-volume "$(pwd)":/developer/nodejs/node-bind-mound-project`: This is the bind mount instruction.
        - `v`: The flag for creating a volume mount.
        - `"$(pwd)"`: This is a shell command substitution.
            - `pwd` stands for "print working directory." When executed, it returns the absolute path of your current directory on the host machine.
            - `$()` captures the output of `pwd`. So, if you are in `/home/user/my-node-app` on your host, this part resolves to `/home/user/my-node-app`.
        - `:`: Separates the host path from the container path.
        - `/developer/nodejs/node-bind-mound-project`: This is the absolute path inside the container where the contents of `$(pwd)` (your host directory) will be mounted.
        - **What it does:** It establishes a real-time, two-way synchronization between your host directory (where your project source code is) and the specified directory inside the container. Any changes you make to files in your local project directory will instantly be reflected inside the running container, and vice-versa. This is incredibly useful for development because you can edit your code on your host machine using your favorite IDE and see the changes take effect in the container without rebuilding the image or restarting the container (if your application has hot-reloading).
    - `app-bind-mount-node:latest`: The name and tag of the image to run. This suggests an image specifically built to use bind mounts, perhaps one that doesn't have the application source code baked into it, or one that expects to run with external source code mounted.

This set of commands covers essential Docker operations, from cleaning up your system to building images and running containers with advanced features like port mapping and bind mounts, which are foundational for a DevOps workflow.
